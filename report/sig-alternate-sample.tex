% This is "sig-alternate.tex" V2.1 April 2013
% This file should be compiled with V2.5 of "sig-alternate.cls" May 2012
%
% This example file demonstrates the use of the 'sig-alternate.cls'
% V2.5 LaTeX2e document class file. It is for those submitting
% articles to ACM Conference Proceedings WHO DO NOT WISH TO
% STRICTLY ADHERE TO THE SIGS (PUBS-BOARD-ENDORSED) STYLE.
% The 'sig-alternate.cls' file will produce a similar-looking,
% albeit, 'tighter' paper resulting in, invariably, fewer pages.
%
% ----------------------------------------------------------------------------------------------------------------
% This .tex file (and associated .cls V2.5) produces:
%       1) The Permission Statement
%       2) The Conference (location) Info information
%       3) The Copyright Line with ACM data
%       4) NO page numbers
%
% as against the acm_proc_article-sp.cls file which
% DOES NOT produce 1) thru' 3) above.
%
% Using 'sig-alternate.cls' you have control, however, from within
% the source .tex file, over both the CopyrightYear
% (defaulted to 200X) and the ACM Copyright Data
% (defaulted to X-XXXXX-XX-X/XX/XX).
% e.g.
% \CopyrightYear{2007} will cause 2007 to appear in the copyright line.
% \crdata{0-12345-67-8/90/12} will cause 0-12345-67-8/90/12 to appear in the copyright line.
%
% ---------------------------------------------------------------------------------------------------------------
% This .tex source is an example which *does* use
% the .bib file (from which the .bbl file % is produced).
% REMEMBER HOWEVER: After having produced the .bbl file,
% and prior to final submission, you *NEED* to 'insert'
% your .bbl file into your source .tex file so as to provide
% ONE 'self-contained' source file.
%
% ================= IF YOU HAVE QUESTIONS =======================
% Questions regarding the SIGS styles, SIGS policies and
% procedures, Conferences etc. should be sent to
% Adrienne Griscti (griscti@acm.org)
%
% Technical questions _only_ to
% Gerald Murray (murray@hq.acm.org)
% ===============================================================
%
% For tracking purposes - this is V2.0 - May 2012

\documentclass{sig-alternate-05-2015}


\begin{document}

% Copyright
%\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
%\setcopyright{rightsretained}
%\setcopyright{usgov}
%\setcopyright{usgovmixed}
%\setcopyright{cagov}
%\setcopyright{cagovmixed}


% DOI
%\doi{10.475/123_4}

% ISBN
%\isbn{123-4567-24-567/08/06}

%Conference
%\conferenceinfo{PLDI '13}{June 16--19, 2013, Seattle, WA, USA}

%\acmPrice{\$15.00}

%
% --- Author Metadata here ---
%\conferenceinfo{WOODSTOCK}{'97 El Paso, Texas USA}
%\CopyrightYear{2007} % Allows default copyright year (20XX) to be over-ridden - IF NEED BE.
%\crdata{0-12345-67-8/90/01}  % Allows default copyright data (0-89791-88-6/97/05) to be over-ridden - IF NEED BE.
% --- End of Author Metadata ---

\title{ML Exercise 2 - Group 19}
\subtitle{Classification Tasks}
%
% You need the command \numberofauthors to handle the 'placement
% and alignment' of the authors beneath the title.
%
% For aesthetic reasons, we recommend 'three authors at a time'
% i.e. three 'name/affiliation blocks' be placed beneath the title.
%
% NOTE: You are NOT restricted in how many 'rows' of
% "name/affiliations" may appear. We just ask that you restrict
% the number of 'columns' to three.
%
% Because of the available 'opening page real-estate'
% we ask you to refrain from putting more than six authors
% (two rows with three columns) beneath the article title.
% More than six makes the first-page appear very cluttered indeed.
%
% Use the \alignauthor commands to handle the names
% and affiliations for an 'aesthetic maximum' of six authors.
% Add names, affiliations, addresses for
% the seventh etc. author(s) as the argument for the
% \additionalauthors command.
% These 'additional authors' will be output/set for you
% without further effort on your part as the last section in
% the body of your article BEFORE References or any Appendices.

\numberofauthors{3} %  in this sample file, there are a *total*
% of EIGHT authors. SIX appear on the 'first-page' (for formatting
% reasons) and the remaining two appear in the \additionalauthors section.
%
\author{
% You can go ahead and credit any number of authors here,
% e.g. one 'row of three' or two rows (consisting of one row of three
% and a second row of one, two or three).
%
% The command \alignauthor (no curly braces needed) should
% precede each author name, affiliation/snail-mail address and
% e-mail address. Additionally, tag each line of
% affiliation/address with \affaddr, and tag the
% e-mail address with \email.
%
% 1st. author
\alignauthor
Lukas Stanek \\
       \affaddr{Technical University of Vienna}\\
       \affaddr{Karlsplatz 13}\\
       \affaddr{1040, Vienna}\\
       \email{----}
% 2nd. author
Thomas Appler \\
       \affaddr{Technical University of Vienna}\\
       \affaddr{Karlsplatz 13}\\
       \affaddr{1040, Vienna}\\
       \email{----}
% 3rd. author
\alignauthor
Marten Sigwart \\
       \affaddr{Technical University of Vienna}\\
       \affaddr{Karlsplatz 13}\\
       \affaddr{1040, Vienna}\\
       \email{e1638152@student.tuwien.ac.at}
}
% There's nothing stop
% Just remember to make sure that the TOTAL number of authors
% is the number that will appear on the first page PLUS the
% number that will appear in the \additionalauthors section.

\maketitle


\section{Introduction}
Our task was to apply 4 different classification algorithms to 4 different data sets. Hereby, we had to experiment with different parameter settings of the classification algorithm, evaluate the performance by choosing appropriate performance measures and compare results among classifiers and data sets. We also had to perform some pre-processing steps on the data prior to applying the classifiers and study the impact of those pre-processing methods.

\subsection{4 data sets}
We chose four different data sets for the task. We chose data sets which varied in size, varied in the number of attributes and varied in the number of instances. Further we tried to pick data sets with different numbers of classes. Some data sets had missing values to take into account.

The four data sets we chose are:

\begin{itemize}
\item Letter Recognition
\item Internet Advertisements
\item Leukemia
\item Congressional Voting
\end{itemize}

\subsubsection{Data Set 1: Letter Recognition}
TODO\\
\subsubsection{Data Set 2: Internet Advertisements}
TODO\\
\subsubsection{Data Set 3: Leukemia}
TODO\\
\subsubsection{Data Set 4: Congressional Voting}
TODO\\


\subsection{4 classification algorithms}
TODO\\

\subsubsection{Algorithm 1: K-Nearest Neighbors}
TODO\\
\subsubsection{Random Forest: Random Forrest}
TODO\\
\subsubsection{Decision Tree - 48J: Decision Tree}
TODO\\
\subsubsection{Bayes Network: Bayes??}
TODO\\


% Section Data Set 1
\section{Data Set 1: Letter Recognition}
The objective for this data set is to predict a letter shown on a rectangular, black and white, display. There are 16 numerical features  provided for determining the correct letter. These attributes provide information about statistical properties of the letter like total number of pixels, width, mean of x-axis pixels, etc.
All of these values were then scaled into a range from 0 through 15. The 26 capital letters to predict in this set were taken from 20 different fonts. The letters are more or less evenly spread over the 20.000 instances, within a range of 734 to 813 occurrences. This data set contains no missing values. For comparable results 10-fold cross validation was used to measure the algorithms precision.
As for performance criteria with this data set only the percentage of correctly classified instances will be considered. The reason for this being that if a letter is wrongly classified, it doesn't matter which other letter was recognized instead of the correct one. 
\\
\subsection{Preprocessing}
As the data set was only provided as CSV file without header row, we added a header row for displaying the attribute names in Weka and therefore facilitating the analysis of the results. 
\\
\subsection{K-Nearest Neighbors}
In order to be able to compare the results we always used the same number of neighbors: 1,2,3,4,5,6,8,10,16,20,40,100.\\
The algorithm is generally very fast, even with 100 neighbors, it is usually finished within 30 seconds. 
\subsubsection{Default implementation}
At first we started out using the default KNN implementation of Weka with default settings. The defaults are a \emph{LinearNN} search algorithm with the \emph{Eucledian distance} as distance function. We started out with increasing the amount of neighbors starting at one. Though with this settings we got the best results using just the nearest neighbor. 
\\\\
\begin{tabular}{ l | c |c }
\textbf{K} & \textbf{\% Correct} & \textbf{\% Wrong} \\
1 & 95.96 & 4.04 \\
2 & 94.925 & 5.075 \\
3 & 95.635 & 4.365 \\
\end{tabular}
\paragraph{}In order to improve the results we started with weighting the neighbors after their distance which helped us further improving the results. The best results where achieved by weighting the neighbors \emph{1/distance}. While the results yielded by the weighting function \emph{1-distance} where also better than without weighting, the were not as good.
\\\\
\begin{tabular}{ l | c | c }
\textbf{K} & \textbf{\% Correct} & \textbf{\% Wrong} \\
1 & 95.96 & 4.04 \\
2 & 95.99& 4.01\\
3 & 96.04 & 3.96 \\
\textbf{4} & \textbf{96.115} & \textbf{3.885} \\
5 & 96.03 & 3.97 \\
6 & 96.015 & 3.985 \\
8 & 95.75 & 4.25 \\
\end{tabular}
\paragraph{}With high values for K the prediction rates get worse. 
\\\\
\begin{tabular}{ l | c | c }
\textbf{K} & \textbf{\% Correct} & \textbf{\% Wrong} \\
40 & 90.915 & 9.085 \\
100 &  84.3 & 15.7 \\
\end{tabular}
\subsubsection{Manhattan Distance} did not improve our prediction, although again when the neighbors were weighted by their distance the success rate improved.
\subsubsection{Chebyshev Distance} also did not improve the result, as it only takes the distance between the attributes which are farthest away from each other as result. As for weighting again, the results improved slightly when using weighted neighbors.
\subsubsection{KD Tree Search Method} improves the run time of the classification significantly. The time for evaluating the models with 10-folds cross validation decreased by 66\%. 

\subsection{Random Forest}
The default settings for Random Forests are 100 Trees with unlimited depth, the number of randomly chosen features per tree is calculated by \textit{log\_2(\#predictors) + 1}.
\paragraph{Number of Trees} We started out with the default settings and varying the number of trees, starting at 100 trees. The result yielded was already at 96.41\% accuracy. Further increasing the number of trees improved the result continuously, but also increased the computation time. 
\\\\
\begin{tabular}{ c | c | c }
\textbf{\# Trees} & \textbf{\% Accuracy} & \textbf{Computation time (s)} \\
50 & 96.10\% & 3.1s \\
100 & 96.41\% & 6.55s \\
200 & 96.53\% & 12.33s \\
300 & 96.51\% & 19.13s \\
400 & 96.54\% & 24.46s \\
500 & 96.58\% & 30.66s\\
\end{tabular}

\paragraph{}Though the performance is improving with the number of trees, the improvements are getting smaller. While an increase of trees from 50 to 100 trees results in a gain of 0.3 percent, the increase from 400 to 500 trees only gains 0.04 percent accuracy. 
\subsubsection{Increasing Execution Slots}For computing a 10-fold cross-validation at 500 trees on one single thread, the taken time was 5:55min. In order to improve this, the number of execution slots (=threads) can be increased. When repeating the same operation with 10 slots our computation time improved to 1:56min. \\
Using 50 threads we calculated a model with 1000 trees, which yielded the best result so far with an accuracy of \emph{96.63\%}. 
\subsubsection{Modifying number of features per tree}
Through varying the number of features which will be selected per tree, we tried to increase the accuracy. \\
Results for \emph{\#Features: 3}:\\
\begin{tabular}{ c | c | c }
\textbf{\# Trees} & \textbf{\% Accuracy} \\
100 & 96.51\% \\
200 & 96.66\% \\
300 & 96.78\% \\
400 & 96.75\% \\
\end{tabular}

\subsubsection{Modifying tree depth}


\subsection{Decision Tree - 48J}
TODO\\
\subsection{Bayes Network}
TODO\\
\subsection{Conclusion}
TODO\\


% Section Data Set 2
\section{Data Set 2: Internet Advertisements}
This data set contains information on different banners/images on websites. The classification task on hand is to determine whether or not an instance is an advertisement or not. A possible use case for this data set would be to remove all adverts from a given website. Some attributes include the geometry of the images (if available), as well as phrases occurring in the URL, the image's URL and alt text, the anchor text and words near the anchor text.

The data set contains a total of 3279 instances, 2821 of which are non-advertisements, 458 are advertisements. Further the data set contains a total of 1558 attributes, 3 of which are continuous variables, the other ones all binary. 28\% of instances are missing one or more of the continuous variables.


\subsection{Preprocessing}
The data set, was contained in two files, one with file ending .name containing all the names of attributes, the other one with ending .data containing the data in a comma-separated format. As Weka prefers data in the ARFF format, we had to do some transformations on the data set prior to loading it into Weka. This was done by first adding the attribute names as header row into the .data file, and saving that file as a CSV file. This file could then be converted by Weka's CSV converter to get the desired ARFF format.

\subsection{K-Nearest Neighbours}
TODO\\
\subsection{Random Forest}
TODO\\
\subsection{Decision Tree - 48J}
TODO\\
\subsection{Bayes Network}
TODO\\
\subsection{Conclusion}
TODO\\


% Section Data Set 3
\section{Data Set 3: Leukemia}
TODO\\
\subsubsection{Preprocessing}
TODO what preprocessing was done\\
\subsubsection{K-Nearest Neighbours}
TODO\\
\subsubsection{Random Forest}
TODO\\
\subsubsection{Decision Tree - 48J}
TODO\\
\subsubsection{Bayes Network}
TODO\\
\subsubsection{Conclusion}
TODO\\


% Section Data Set 4
\section{Data Set 4: Congressional Voting}
TODO\\
\subsubsection{Preprocessing}
TODO what preprocessing was done\\
\subsubsection{K-Nearest Neighbours}
TODO\\
\subsubsection{Random Forest}
TODO\\
\subsubsection{Decision Tree - 48J}
TODO\\
\subsubsection{Bayes Network}
TODO\\
\subsubsection{Conclusion}
TODO\\


\section{Conclusion}
TODO\\



\end{document}
